# Apple Stock Price Prediction by Recurrent Neural Network

_Author: Clara Le_

_Date: 22/11/2023_

___

## INTRODUCTION

The stock market plays a vital role in the financial industry in particular and the economic system in general. For example, if stock prices increase, it can result in more spending and higher Gross domestic product (GDP) index, since investors can earn more money and then spend more money on their consumption. In addition, the changes in stock prices also affect significantly to companies market value. High stock price can make companies more appealing to investors and vice versa. However, the stock market is also strongly volatile to many events. For example, when COVID-19 pandemic happened at the year of 2020, the stock market was impacted extremely, and stock prices of many com- panies dropped dramatically. Due to this stock market’s disadvantage, although a good stock price prediction is important for investors to make appropriate decision and then gain significant profits from their investment, this prediction task becomes more challenging. Therefore, this research was conducted at the aim of building an architecture which can generate good prediction for stock prices. Since stock prices are sequential with time series, Recurrent Neural Network (RNN) is an appropriate architecture to be considered in this project. In particular, RNN architectures including standard RNN, Long Short-Term Memory (LSTM) and Gated recurrent unit (GRU) were implemented and their performance were compared to figure out the best architecture among them. In addition, this research also experiments several methods which can contribute to improve model’s performance and reduce overfitting problem, such as time step tuning, Batch Normalization, hyperparameters tuning, and regularization methods.

## EXPERIMENTS

In this project, the training data initially included Apple stock’s close prices from January 04, 2010 to December 30, 2021. After that, this training dataset was divided into a validation set and a training set, with the latest 500 observed close prices were in the validation set. Hence, the final training dataset had close prices from January 04, 2010 to January 06, 2020, with a total of 2519 observations. In addition, the validation dataset included prices ranging from January 07, 2020 to December 30, 2021 (500 rows) and the testing set comprised prices from January 03, 2022 to September 30, 2023 (438 rows). A diagram presenting the time period of training set, validation set and testing set were shown below.

<a href="url"><img src="https://github.com/Tien-le98/Apple-Stock-Price-Prediction/blob/main/dataspliting.png" align="center"></a>

Because of the difference in Apple close price’s trend between the training, validation set and the testing set, employing actual prices can affect negatively to model’s performance. Therefore, instead of using actual close prices, their residuals was computed by taking logarithm then calculating differences between 2 adjacent days, and multiplying these differences with 100. After that, these residuals can be seen as percentage changes in stock price. These percentage changes were employed to train RNN architectures.

### Experiment 1

The first experiment was carried out to compare model’s performance on the original dataset and the pre-processed datasets, in order to figure out if pre-processing steps are necessary for model’s performance to be improved. 

A baseline RNN model was built with 1 input layer, 1 SimpleRNN (Simple Recurrent Neural Network) layer and 1 output layer, using Tanh activation function. Mean squared error (MSE) values were tracked as loss values. The RNN layer employed in this baseline model had 50 units, and the output layer only had 1 unit. In addition, this baseline RNN used Adam optimizer with learning rate of 0.01, batch size of 30, and the number of epochs of 100. However, Early stopping method was employed to prevent models from potential overfitting problem, hence this model usually converged before reaching 100 epochs. This early stopping method had patience of 5, and tracked validation loss values. Time-step used in this experiments was set to 1. This baseline model was trained on the original dataset, a dataset pre-processed by using Standard scaling method, and a dataset pre-processed by Max-Min scaling method. 
+ In terms of the original dataset, the baseline RNN model converged after around 8 epochs with the training loss of 2.6429 and the validation loss of 5.6919. On the contrary, this baseline model performed better on the pre-processed datasets.
+ To standard scaled training dataset, this model achieved training loss of 1.0070 and validation loss of 2.1407 after 9 epochs, while the figure for max-min scaled dataset were 0.0060 and 0.0126 respectively. Although both the training loss and validation loss on the max-min scaled dataset were lower than the figure for the standard scaled dataset, this phenomenon can be affected by the way these normalization methods transform data. Therefore, the MSE value between real price and predicted price on validation set were considered instead. After converting scaled data to original close prices, the baseline model trained on standard scaled dataset achieved the MSE value of 998.6 while the figure for max-min scaled dataset was over 2690, which indicated that the standard scaled dataset can improve model’s performance better than max-min scaling method. Hence, the standard scaled dataset was employed for the next experiments.
+ In addition, through this experiment, it can be proved that the dataset should be pre-processed before training RNN models in order to improve model’s performance since loss values of models trained on the pre-processed datasets were significantly lower than the figure for the original dataset. 

### Experiment 2

The second experiment was implemented to find out the best architecture which can achieve the lowest MSE value for its stock price prediction, among several different architectures including standard RNN, LSTM, and GRU. Besides, this experiment was also conducted to figure out if different number of hidden layers can affect model performance. Three models with different number of LSTM hidden layers was conducted, and three GRU models with different number of GRU hidden layers also carried out. The training loss, validation loss, and MSE values of these networks were shown the below table. 

<a href="url"><img src="https://github.com/Tien-le98/Apple-Stock-Price-Prediction/blob/main/lstm_gru.png" align="center" ></a>

The architecture obtained the lowest MSE value of close price was LSTM architecture with 4 LSTM hidden layers, which means that this architecture was the best model among all other considered networks. Besides, the GRU architecture with 4 GRU hidden layers also performed pretty as good as this best LSTM network with MSE of around 121.3366, which was just slightly lower than the figure for the best LSTM (about 121.0724). 

Though this second experiments, the number of hidden layers in RNN architecture can affect to model’s performance. If there is only 1 layer included, models may not complicated enough to capture much important information of the input data, resulting in bad performance. To the dataset employed in this project, models with multiple hidden layers performed better than other simpler models. It was proved through the MSE values achieved between simple models and deeper models.

### Experiment 3

The third experiment was hyperparameters tuning, particularly, several hyperparameters such as time-steps, activation functions, optimizers and learning rates, were tuned in order to find out the best architecture, based on evaluation metric of MSE. Different combination of these parameters was applied on the best LSTM architecture to find out the optimal combination which can improve the model’s performance the most. Four different time steps considered were 10, 30, 50, and 100. In addition, this tuning step included 5 activation functions such as Tanh, ReLU, LeaklyReLU, ELU, and SELU, 3 optimizers including SGD, Adam, and Nadam, and 2 different learning rates of 0.01 and 0.001. Time-step tuning was implemented first, then the best LSTM model with the optimal time-step was set to run though other hyperparametes tuning stage. In time-step tuning process, the LSTM model with time step of 30 achieved the lowest MSE value on Apple stock’s close price, which was about 131.6977. This MSE value was pretty higher than the figure for the best LSTM with time-step of 1 found in the second experiment. However, the LSTM model with time-step of 30 was still selected to assess further since time-step of 1 can be strongly sensitive to outliers and extreme values, which can lead to noisy values, and affect negatively to model’s performance when model was evaluated on the unknown datasets such as the testing dataset. The LSTM architecture with time-step of 30 then was tuned with different hyperparameters, and its performance was presented in the below table.

<a href="url"><img src="https://github.com/Tien-le98/Apple-Stock-Price-Prediction/blob/main/tuning_hyperparameters.png" align="center"></a>

Among 30 different combinations of hyperparameters, the best architecture was LSTM with time-step of 30, activation function of SELU, optimizer of SGD and its learning rate of 0.001. This best architecture was then evaluated on the standard scaled validation set, and it obtained MSE value of close price was about 198.2626. In addition, this best model’s MSE value was significantly lower than the figure for the baseline RNN network. Several reasons can result in this improvement as belows:
+ First, this best LSTM has a deeper network with 4 hidden layers while the baseline RNN only has 1 hidden layer, which can help model to capture more important information of the input data.
+ Second, time-step also can contribute to improve model’s performance. Because the baseline RNN employed time-step of 1, which can gather much noisy data, and affect negatively to model’s performance. On the contrary, after time-step tuning, the best LSTM used timestep of 30, which was seen as an appropriate choice to decrease MSE value and prevent the model from being too sensitive to extreme values.
+ Third, the SELU activation function can contributed in this improvement since it can mitigate vanishing gradient problem and push the mean of activation function closer to 0. 

### Experiment 4

The fourth experiment was implemented by applying different number of layers of Batch Normalization on the best network found in the previous experiments, to figure out if Batch Normalization can improve model’s performance. Three models with different number of Batch Normalization layers was built. According to this experiment’s results, Batch Normalization did not contribute to improve model’s performance. In particular, the LSTM with 1 layer of Batch Normalization obtained MSE of 245.6689, the LSTM with 2 layers of Batch Normalization achieved MSE of 299.5769, while the figure for the LSTM with 3 layers of Batch Normalization was about 354.3303. These MSE values were higher than the observed MSE of the best LSTM in the third experiment, hence, Batch Normalization was not added to the best LSTM architecture since it makes the model perform worse. 

In addition, it can be seen that the validation loss was always two times higher than the figure for training loss, which means that the overfitting problem can happened during training process. Three main regularization methods including L1 regularization, L2 regularization, and Dropout regularization, were experimented to eliminate this overfitting problem in the fifth experiment.

### Experiment 5

The fifth experiment focused on using regularization methods such as Lasso regularizer (L1), Ridge regularizer (L2), and Dropout regularization since overfitting problem occurred during training models. 
+ When L1 regularization was added to the best LSTM, its training loss was about 1.0039 and validation loss was 2.2215, which were pretty similar to the figure of the best LSTM without L1 regularization, meaning that L1 regularization did not contribute much in reducing overfitting problem. Howver, the model with L1 performed better on the validation dataset than the model without L1, since its MSE value was only 138.1523 while the figure for the model without L1 was 198.2626.
+ Like L1 regularization, L2 regularization did not reduce the overfitting problem since its training loss was 1.0039 and its validation loss was 2.2215. However, it also improved model’s performance since the best LSTM architecture with L2 regularization achieved lower MSE (around 152.4191) than the best LSTM architecture without L2. However, its MSE was still higher than the figure for the best LSTM with L1 regularization, therefore, the LSTM with L1 was chosen to experiment many layers of Dropout in the effort of eliminating overfitting problem.
+ Then different number of Dropout layers were added to this best architecture in order to figure out the effect of Dropout layers on model’s performance and overfitting problem. But Dropout layers also did not reduce the difference between training loss and validation loss, meaning that the overfitting problem was still not handled. However, adding Dropout layers to model can improve its performance. In particular, the LSTM with 4 Dropout layers and dropout rate of 0.2, achieved the lowest MSE of close price, hence it became the best LSTM in this project.

<a href="url"><img src="https://github.com/Tien-le98/Apple-Stock-Price-Prediction/blob/main/lstm_dropout.png" align="center"></a>

### Experiment 6

The best network was assessed on the testing dataset of Apple stock’s close price before being evaluated on other stock’s testing dataset in the last experiment. Its MSE on the Apple testing dataset was upto 8936.6207, which was significantly higher than its figure on the validation set. This MSE value showed that this best LSTM architecture did not perform well on the unknown dataset, particularly the testing set, and its generalization error was dramatically high. However, this bad performance can be because of the different stock price’s trend between the training, validation set, and the testing set. As discussed above, the COVID-19 pandemic affected negatively to stock price, leading to two different trends in the training, validation set and the testing set. Because the training and validation dataset included stock prices before the year of 2020, hence Apple’s stock price had an upward trend. However, in the testing dataset which included data from the beginning of 2022, due to COVID-19 pandemic, this trend changed its direction, fluctuated and fell down sharply. Therefore, when this best LSTM model was trained by data in the training set, this network only can perform well on the validation set since price trend in this validation set was pretty similar to price trend in the training set. In addition, this best LSTM performed worse on the testing set since it included data with price trend much different from price trend in the training data.

<a href="url"><img src="https://github.com/Tien-le98/Apple-Stock-Price-Prediction/blob/main/lstm_performance.png" align="center"></a>

Besides Apple stock’s close price, this best LSTM architecture was also evaluated on close price of other 29 stocks. Its performance was presented in the below table. Since all other stock prices also were negatively affected by the COVID-19 pandemic, this best network can not perform well and generate good predictions. However, its performance on MRK stock was the greatest with the lowest MSE value of close price. This can be because MRK is stock of Merck & Co., Inc., which is an American multinational pharmaceutical company. In COVID-19 expansion, pharmaceutical companies can receive more investment since they play vital role in preventing and slowing down the spread of the pandemic. Therefore, their stock price may not be affected significantly like stocks of other companies.

<a href="url"><img src="https://github.com/Tien-le98/Apple-Stock-Price-Prediction/blob/main/otherstock_test.png" align="center"></a>

## CONCLUSION

Through results of experiments in this project, several main points were defined as below:
+ Pre-processed data steps are important in improving model’s performance. In particular, Standard scaling method can improve model’s performance better than other pre-processing methods, particularly Max-min scaling method.
+ In comparison between different architectures such as standard RNN, LSTM with different number of hidden LSTM layers, and GRU network with different number of GRU hidden layers, the LSTM network with 4 hidden layers had the greatest performance. The reason for this experiment can be because deeper networks can capture more important information from input data than other simpler models. It was proved through LSTM and GRU with 4 hidden layers performed better than those models with only 1 hidden layer. There is no significant difference between performance of LSTM and GRU, which means that these architectures work pretty as good as each other.
+ Through tuning stage, time-step was seen that it can affect model’s performance. When time step increased, model intended to perform worse. However, if time-step was too small, the model can be too sensitive to noisy data in the training dataset. Therefore, time-step should be considered thoroughly when training models. In addition, the best LSTM with time-step of 30, SGD optimizer, and SELU activation function obtained the lowest MSE value (around 198) on the validation dataset because time-step of 30 can help this model to capture more general trend of stock prices instead of being sensitive to extreme values, and SELU activation function can alleviate vanishing gradient, and non-zero mean problems. Therefore, hyperparameters can affect model’s performance, tuning hyperparameters can contribute in choosing the best network, which can result in smaller MSE value, meaning that better model’s performance.
+ In this project, Batch Normalization was not seen as a good choice to improve model’s performance since MSE values of models built with Batch Normalization layers (about 245-354) were higher than the figure for the model constructed without it. Because overfitting problem happened during training process, L1, L2 and Dropout regularization was experimented to mitigate this problem. But these methods did not contribute much in decreasing the difference between training loss and validation loss values, which means that the overfitting problem was not addressed. However, L1 regularization can reduce the value of MSE, meaning that model’s better performance. Like L1 regularization, Dropout regularization also can improve model’s performance further, and the best LSTM was the architecture built with both L1 regularization and 4 Dropout layers.
+ The best model performed pretty well on the validation dataset with the MSE value of nearly 125. However, it works very badly on the testing dataset with MSE value of over 8936. This problem happened can be due to the significantly negative effect of COVID-19 pandemic on stock prices, leading to different price’s trend in the training set, validation set and the testing set. Therefore, this model can generate pretty good prediction on the validation set, but worse prediction on the testing set.
+ After evaluating this best network on the testing data of other stocks, the same problem was observed since their MSE values were extremely higher, except for MRK stock. This can be because this MRK stock was stock of an American multinational pharmaceutical company, its price’s trend was not affected as significantly as other stocks by the COVID-19 expansion, because pharmaceutical companies play a vital role in preventing the spread of the pandemic, they can receive more investment and their stock prices may not dropped sharply like other stocks.
